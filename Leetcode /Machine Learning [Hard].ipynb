{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3040f63e-dd3f-4581-afdb-e043f80ad4e1",
   "metadata": {},
   "source": [
    "## Machine Learning Hard "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db767b3b-edff-456f-9ad0-e9bb40d0c579",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1be34a-27fa-4589-a948-6f386128c621",
   "metadata": {},
   "source": [
    "Decision Tree Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af049d91-f326-4060-842b-df751bd4d2dc",
   "metadata": {},
   "source": [
    "Write a Python function that implements the decision tree learning algorithm for classification. The function should use recursive binary splitting based on entropy and information gain to build a decision tree. It should take a list of examples (each example is a dict of attribute-value pairs) and a list of attribute names as input, and return a nested dictionary representing the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f9b2527-a4f1-4b46-a815-068130038493",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_entropy(labels):\n",
    "    label_counts = Counter(labels)\n",
    "    total_count = len(labels)\n",
    "    entropy = -sum((count / total_count) * math.log2(count / total_count) for count in label_counts.values())\n",
    "    return entropy\n",
    "\n",
    "def calculate_information_gain(examples, attr, target_attr):\n",
    "    total_entropy = calculate_entropy([example[target_attr] for example in examples])\n",
    "    values = set(example[attr] for example in examples)\n",
    "    attr_entropy = 0\n",
    "    for value in values:\n",
    "        value_subset = [example[target_attr] for example in examples if example[attr] == value]\n",
    "        value_entropy = calculate_entropy(value_subset)\n",
    "        attr_entropy += (len(value_subset) / len(examples)) * value_entropy\n",
    "    return total_entropy - attr_entropy\n",
    "\n",
    "def majority_class(examples, target_attr):\n",
    "    return Counter([example[target_attr] for example in examples]).most_common(1)[0][0]\n",
    "\n",
    "def learn_decision_tree(examples, attributes, target_attr):\n",
    "    if not examples:\n",
    "        return 'No examples'\n",
    "    if all(example[target_attr] == examples[0][target_attr] for example in examples):\n",
    "        return examples[0][target_attr]\n",
    "    if not attributes:\n",
    "        return majority_class(examples, target_attr)\n",
    "    \n",
    "    gains = {attr: calculate_information_gain(examples, attr, target_attr) for attr in attributes}\n",
    "    best_attr = max(gains, key=gains.get)\n",
    "    tree = {best_attr: {}}\n",
    "    \n",
    "    for value in set(example[best_attr] for example in examples):\n",
    "        subset = [example for example in examples if example[best_attr] == value]\n",
    "        new_attributes = attributes.copy()\n",
    "        new_attributes.remove(best_attr)\n",
    "        subtree = learn_decision_tree(subset, new_attributes, target_attr)\n",
    "        tree[best_attr][value] = subtree\n",
    "    \n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ab1089-2eb5-4e1e-99f7-1b660f073887",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c9c976-e2de-4fd7-a583-8d12d5da0adf",
   "metadata": {},
   "source": [
    "Probelem Pegasos Kernel SVM Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fe66283-713e-4e07-b3bd-34ceca4d0d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def linear_kernel(x, y):\n",
    "    return np.dot(x, y)\n",
    "\n",
    "def rbf_kernel(x, y, sigma=1.0):\n",
    "    return np.exp(-np.linalg.norm(x-y)**2 / (2 * (sigma ** 2)))\n",
    "\n",
    "def pegasos_kernel_svm(data, labels, kernel='linear', lambda_val=0.01, iterations=100, sigma=1.0):\n",
    "    n_samples = len(data)\n",
    "    alphas = np.zeros(n_samples)\n",
    "    b = 0\n",
    "\n",
    "    for t in range(1, iterations + 1):\n",
    "        for i in range(n_samples):\n",
    "            eta = 1.0 / (lambda_val * t)\n",
    "            if kernel == 'linear':\n",
    "                kernel_func = linear_kernel\n",
    "            elif kernel == 'rbf':\n",
    "                kernel_func = lambda x, y: rbf_kernel(x, y, sigma)\n",
    "    \n",
    "            decision = sum(alphas[j] * labels[j] * kernel_func(data[j], data[i]) for j in range(n_samples)) + b\n",
    "            if labels[i] * decision < 1:\n",
    "                alphas[i] += eta * (labels[i] - lambda_val * alphas[i])\n",
    "                b += eta * labels[i]\n",
    "\n",
    "    return np.round(alphas,4).tolist(), np.round(b,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68176e3e-f610-42d2-a64f-7ce6191a9780",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
